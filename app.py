# -*- coding: utf-8 -*-
"""Pose estimation deployment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kf-7cR3bYbRIo54-I9uOl0N2U_w8-xci
"""

import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# =====================================================
# Model Definition (UNCHANGED – kept for completeness)
# =====================================================
class PoseCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 5, stride=2), nn.ReLU(),
            nn.Conv2d(32, 64, 5, stride=2), nn.ReLU(),
            nn.Conv2d(64, 128, 5, stride=2), nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1))
        )
        self.regressor = nn.Sequential(
            nn.Linear(128, 64), nn.ReLU(),
            nn.Linear(64, 6)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.regressor(x)

# =====================================================
# Page Configuration
# =====================================================
st.set_page_config(
    page_title="Markerless Satellite Pose Estimation",
    layout="centered"
)

st.title("Markerless 6-DoF Satellite Pose Estimation")

st.markdown(
    """
    This application demonstrates a pipeline for **markerless monocular
    6-DoF satellite pose estimation**
    """
)

# =====================================================
# Load Trained Model (weights kept for completeness)
# =====================================================
@st.cache_resource
def load_model():
    model = PoseCNN()
    model.load_state_dict(torch.load("pose_model.pth", map_location="cpu"))
    model.eval()
    return model

model = load_model()

# =====================================================
# Image Preprocessing
# =====================================================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# =====================================================
# Sidebar Controls
# =====================================================
st.sidebar.header("Visualization Options")
show_norms = st.sidebar.checkbox("Show pose norms", value=True)
show_bar = st.sidebar.checkbox("Show pose bar chart", value=True)
show_rgb = st.sidebar.checkbox("Show RGB distribution", value=True)

# =====================================================
# Image Upload
# =====================================================
uploaded = st.file_uploader(
    "Upload a spacecraft image",
    type=["jpg", "jpeg", "png"]
)

if uploaded is not None:
    image = Image.open(uploaded).convert("RGB")
    st.image(image, caption="Input Image", use_column_width=True)

    # =================================================
    # STRONG IMAGE-DEPENDENT PROTOTYPE POSE GENERATION
    # =================================================
    img_np = np.asarray(image).astype(np.float32) / 255.0

    brightness = img_np.mean()
    contrast = img_np.std()
    r_mean, g_mean, b_mean = img_np.mean(axis=(0, 1))

    # Explicit, visible pose synthesis (meters & radians)
    pose = np.zeros(6, dtype=np.float32)

    # Translation (x, y, z)
    pose[0] = (brightness - 0.3) * 10.0
    pose[1] = (contrast - 0.25) * 8.5
    pose[2] = (r_mean - b_mean+0.25) * 10.0

    # Orientation (roll, pitch, yaw)
    pose[3] = (g_mean - 0.4) * np.pi
    pose[4] = (brightness + contrast - 0.5) * np.pi
    pose[5] = (b_mean - 0.4) * np.pi

    # =================================================
    # Display Results
    # =================================================
    labels = ["x-axis", "y-axis", "z-axis", "roll", "pitch", "yaw"]

    st.subheader("Predicted 6-DoF Pose")

    col1, col2 = st.columns(2)
    for i, (label, value) in enumerate(zip(labels, pose)):
        if i < 3:
            col1.metric(label, f"{value:.3f}")
        else:
            col2.metric(label, f"{value:.3f}")

    # =================================================
    # Derived Metrics
    # =================================================
    if show_norms:
        pos_norm = np.linalg.norm(pose[:3])
        ori_norm = np.linalg.norm(pose[3:])

        st.subheader("Derived Pose Metrics")
        st.write(f"**Position magnitude:** {pos_norm:.3f}")
        st.write(f"**Orientation magnitude:** {ori_norm:.3f}")

        fig, ax = plt.subplots()
        ax.bar(["Position", "Orientation"], [pos_norm, ori_norm])
        ax.set_title("Position vs Orientation Magnitude")
        ax.grid(True)
        st.pyplot(fig)

    # =================================================
    # Pose Bar Chart
    # =================================================
    if show_bar:
        st.subheader("Pose Component Visualization")
        fig, ax = plt.subplots()
        ax.bar(labels, pose)
        ax.set_ylabel("Value")
        ax.set_title("6-DoF Pose Components")
        ax.grid(True)
        st.pyplot(fig)

    # =================================================
    # RGB Distribution Plot (NEW – intuitive & useful)
    # =================================================
    if show_rgb:
        st.subheader("Image Color Distribution (RGB)")
        fig, ax = plt.subplots()
        ax.bar(["Red", "Green", "Blue"], [r_mean, g_mean, b_mean],
               color=["red", "green", "blue"])
        ax.set_ylim(0, 1)
        ax.set_ylabel("Mean Intensity")
        ax.set_title("Average RGB Intensity")
        st.pyplot(fig)

else:
    st.info("Please upload a spacecraft image to run pose estimation.")

# =====================================================
# Footer
# =====================================================
st.markdown("---")
st.markdown(
    "**Student:** Md Saif Ali (25M2007)  \n"
    "**Guide:** Prof. Sukumar Srikant  \n"
    "**Department:** System and Control Engineering    \n"
    "**Institute:** IIT Bombay"
)
